{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Improve</th>\n",
       "      <th>Super</th>\n",
       "      <th>ImpCrit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>01-10-2011</td>\n",
       "      <td>Get treatment I requested.</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01-10-2011</td>\n",
       "      <td>Provide Gym staff to get Gym up and running!</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01-10-2011</td>\n",
       "      <td>To look at the problems properly and give you the right medication.</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01-10-2011</td>\n",
       "      <td>To be more involved.</td>\n",
       "      <td>Involvement</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>01-10-2011</td>\n",
       "      <td>My drug problem was with Subutex.  I was given methadone which has now made my drug dependency a lot worse.  It would have been better for me to be prescribed Subutex and dealt with like that.</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  \\\n",
       "0  01-10-2011   \n",
       "1  01-10-2011   \n",
       "2  01-10-2011   \n",
       "3  01-10-2011   \n",
       "4  01-10-2011   \n",
       "\n",
       "                                                                                                                                                                                            Improve  \\\n",
       "0                                                                                                                                                                        Get treatment I requested.   \n",
       "1                                                                                                                                                      Provide Gym staff to get Gym up and running!   \n",
       "2                                                                                                                               To look at the problems properly and give you the right medication.   \n",
       "3                                                                                                                                                                              To be more involved.   \n",
       "4  My drug problem was with Subutex.  I was given methadone which has now made my drug dependency a lot worse.  It would have been better for me to be prescribed Subutex and dealt with like that.   \n",
       "\n",
       "             Super  ImpCrit  \n",
       "0  Care/ Treatment      1.0  \n",
       "1  Care/ Treatment      1.0  \n",
       "2  Care/ Treatment      2.0  \n",
       "3      Involvement      2.0  \n",
       "4  Care/ Treatment      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/Hello/Downloads/NHS/New folder/data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "datafinal=data.dropna(axis=0)\n",
    "comment_columns = 'Improve'\n",
    "target_columns = datafinal.columns[2:]\n",
    "y = datafinal[target_columns]\n",
    "X = datafinal[comment_columns]\n",
    "y['ImpCrit'].values[y['ImpCrit'].values > 4] = 5\n",
    "y['ImpCrit']=y['ImpCrit'].abs()\n",
    "Y1=pd.get_dummies(y['Super'],drop_first = True)\n",
    "Y2=pd.get_dummies(y['ImpCrit'],drop_first = True)\n",
    "Y=pd.concat([Y1,Y2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean(instr):\n",
    "    return instr.translate(str.maketrans('', '', string.punctuation))\n",
    "X = X.apply(clean) \n",
    "X = X.replace(r'\\n',  ' ', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open('../input/customerexp/glove.6B.300d.txt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        embedding_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import  sequence\n",
    "max_length = 100\n",
    "embed_size = 300\n",
    "batch_size = 32\n",
    "epochs =100\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenizer.texts_to_sequences(X)\n",
    "Xtrain = sequence.pad_sequences(train_tokenized, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtrain, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "\n",
    "# model definition\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, embed_size))\n",
    "model_rnn.add(SimpleRNN(32))\n",
    "model_rnn.add(Dense(21, activation='sigmoid'))\n",
    "model_rnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_rnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# model definition\n",
    "model_brnn = Sequential()\n",
    "model_brnn.add(Embedding(max_features, embed_size))\n",
    "model_brnn.add(Bidirectional(SimpleRNN(32)))\n",
    "model_brnn.add(Dense(21, activation='sigmoid'))\n",
    "model_brnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_brnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, Dropout, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Embedding(max_features, embed_size, weights=[embedding_matrix]))\n",
    "\n",
    "model_cnn.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(3))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(BatchNormalization())\n",
    "\n",
    "model_cnn.add(Dense(50, activation='relu'))\n",
    "model_cnn.add(Dropout(0.3))\n",
    "model_cnn.add(Dense(21, activation='sigmoid'))\n",
    "\n",
    "model_cnn.summary()\n",
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model_cnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
