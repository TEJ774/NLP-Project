{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Improve</th>\n",
       "      <th>Super</th>\n",
       "      <th>ImpCrit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Get treatment I requested.</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>Provide Gym staff to get Gym up and running!</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>To look at the problems properly and give you ...</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>To be more involved.</td>\n",
       "      <td>Involvement</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>My drug problem was with Subutex.  I was given...</td>\n",
       "      <td>Care/ Treatment</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                            Improve  \\\n",
       "0  2011-10-01                         Get treatment I requested.   \n",
       "1  2011-10-01       Provide Gym staff to get Gym up and running!   \n",
       "2  2011-10-01  To look at the problems properly and give you ...   \n",
       "3  2011-10-01                               To be more involved.   \n",
       "4  2011-10-01  My drug problem was with Subutex.  I was given...   \n",
       "\n",
       "             Super  ImpCrit  \n",
       "0  Care/ Treatment      1.0  \n",
       "1  Care/ Treatment      1.0  \n",
       "2  Care/ Treatment      2.0  \n",
       "3      Involvement      2.0  \n",
       "4  Care/ Treatment      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../input/customerexp/improve.csv',nrows=50)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "datafinal=data.dropna(axis=0)\n",
    "comment_columns = 'Improve'\n",
    "target_columns = datafinal.columns[2:]\n",
    "y = datafinal[target_columns]\n",
    "X = datafinal[comment_columns]\n",
    "y['ImpCrit'].values[y['ImpCrit'].values > 4] = 5\n",
    "y['ImpCrit']=y['ImpCrit'].abs()\n",
    "Y1=pd.get_dummies(y['Super'],drop_first = True)\n",
    "Y2=pd.get_dummies(y['ImpCrit'],drop_first = True)\n",
    "Y=pd.concat([Y1,Y2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean(instr):\n",
    "    return instr.translate(str.maketrans('', '', string.punctuation))\n",
    "X = X.apply(clean) \n",
    "X = X.replace(r'\\n',  ' ', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(5, activation='sigmoid')(clf_output)\n",
    "    \n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(Adam(lr=2e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             Get treatment I requested\n",
       "1           Provide Gym staff to get Gym up and running\n",
       "2     To look at the problems properly and give you ...\n",
       "3                                   To be more involved\n",
       "4     My drug problem was with Subutex  I was given ...\n",
       "5     The prisoner would be able to choose what trea...\n",
       "6     If people would like to be put on medication f...\n",
       "7     Nothing really only the gym and need of staff ...\n",
       "8     Medication  What we get on the outside ie Zopi...\n",
       "9     I would have liked for the IDTS Doctor to have...\n",
       "10                                 Time to get our meth\n",
       "11    Getting back on to Methadone programme can tak...\n",
       "12                              To have longer sessions\n",
       "13                  Access to the doctor without triage\n",
       "14    To come right away not leaving it about 3 or 4...\n",
       "15    I should have gone to the MSU and am still in ...\n",
       "17        Noone likes giving benzos and thats not right\n",
       "18    I would like to have a support group so we can...\n",
       "19              Prescribe zopiclone sometimes I need it\n",
       "21    That it could continue on a permanent weekly b...\n",
       "22    To be able to keep in touch with support worke...\n",
       "24    New checking in and out system I dont like it ...\n",
       "25                                           More staff\n",
       "26                             More access to bathrooms\n",
       "27    To assist with my golf and re introduce me to ...\n",
       "28                                        More sessions\n",
       "Name: Improve, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(X.values, tokenizer, max_len=160)\n",
    "train_labels = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            5125        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 335,147,014\n",
      "Trainable params: 335,147,013\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=160)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 21s 10s/step - loss: 2.2349 - accuracy: 0.1000 - val_loss: 2.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 17s 8s/step - loss: 2.0613 - accuracy: 0.1500 - val_loss: 2.1839 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 17s 8s/step - loss: 1.8989 - accuracy: 0.3000 - val_loss: 2.1422 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "predictions = model.predict(train_input[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
